{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning & The Titanic\n",
    "https://www.kaggle.com/c/titanic/overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "missing values:  \n",
      " Age         177\n",
      "Cabin       687\n",
      "Embarked      2\n",
      "dtype: int64 \n",
      " object cols:  \n",
      " ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# importing data\n",
    "training_data = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# looking at data\n",
    "# print(training_data.head())\n",
    "print(training_data.columns)\n",
    "# print(training_data.shape)\n",
    "object_cols = [col for col in training_data.columns if training_data[col].dtype == \"object\"]\n",
    "\n",
    "missing_val_count_by_column = (training_data.isnull().sum())\n",
    "print(\"missing values: \", \"\\n\", missing_val_count_by_column[missing_val_count_by_column > 0], \"\\n\", \"object cols: \", \"\\n\", object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Pclass  SibSp  Parch   Age     Sex      Fare\n",
      "0         3      1      0  22.0    male    7.2500\n",
      "1         1      1      0  38.0  female   71.2833\n",
      "2         3      0      0  26.0  female    7.9250\n",
      "3         1      1      0  35.0  female   53.1000\n",
      "4         3      0      0  35.0    male    8.0500\n",
      "5         3      0      0   NaN    male    8.4583\n",
      "6         1      0      0  54.0    male   51.8625\n",
      "7         3      3      1   2.0    male   21.0750\n",
      "8         3      0      2  27.0  female   11.1333\n",
      "9         2      1      0  14.0  female   30.0708\n",
      "10        3      1      1   4.0  female   16.7000\n",
      "11        1      0      0  58.0  female   26.5500\n",
      "12        3      0      0  20.0    male    8.0500\n",
      "13        3      1      5  39.0    male   31.2750\n",
      "14        3      0      0  14.0  female    7.8542\n",
      "15        2      0      0  55.0  female   16.0000\n",
      "16        3      4      1   2.0    male   29.1250\n",
      "17        2      0      0   NaN    male   13.0000\n",
      "18        3      1      0  31.0  female   18.0000\n",
      "19        3      0      0   NaN  female    7.2250\n",
      "20        2      0      0  35.0    male   26.0000\n",
      "21        2      0      0  34.0    male   13.0000\n",
      "22        3      0      0  15.0  female    8.0292\n",
      "23        1      0      0  28.0    male   35.5000\n",
      "24        3      3      1   8.0  female   21.0750\n",
      "25        3      1      5  38.0  female   31.3875\n",
      "26        3      0      0   NaN    male    7.2250\n",
      "27        1      3      2  19.0    male  263.0000\n",
      "28        3      0      0   NaN  female    7.8792\n",
      "29        3      0      0   NaN    male    7.8958\n",
      "..      ...    ...    ...   ...     ...       ...\n",
      "861       2      1      0  21.0    male   11.5000\n",
      "862       1      0      0  48.0  female   25.9292\n",
      "863       3      8      2   NaN  female   69.5500\n",
      "864       2      0      0  24.0    male   13.0000\n",
      "865       2      0      0  42.0  female   13.0000\n",
      "866       2      1      0  27.0  female   13.8583\n",
      "867       1      0      0  31.0    male   50.4958\n",
      "868       3      0      0   NaN    male    9.5000\n",
      "869       3      1      1   4.0    male   11.1333\n",
      "870       3      0      0  26.0    male    7.8958\n",
      "871       1      1      1  47.0  female   52.5542\n",
      "872       1      0      0  33.0    male    5.0000\n",
      "873       3      0      0  47.0    male    9.0000\n",
      "874       2      1      0  28.0  female   24.0000\n",
      "875       3      0      0  15.0  female    7.2250\n",
      "876       3      0      0  20.0    male    9.8458\n",
      "877       3      0      0  19.0    male    7.8958\n",
      "878       3      0      0   NaN    male    7.8958\n",
      "879       1      0      1  56.0  female   83.1583\n",
      "880       2      0      1  25.0  female   26.0000\n",
      "881       3      0      0  33.0    male    7.8958\n",
      "882       3      0      0  22.0  female   10.5167\n",
      "883       2      0      0  28.0    male   10.5000\n",
      "884       3      0      0  25.0    male    7.0500\n",
      "885       3      0      5  39.0  female   29.1250\n",
      "886       2      0      0  27.0    male   13.0000\n",
      "887       1      0      0  19.0  female   30.0000\n",
      "888       3      1      2   NaN  female   23.4500\n",
      "889       1      0      0  26.0    male   30.0000\n",
      "890       3      0      0  32.0    male    7.7500\n",
      "\n",
      "[891 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# features to fit model off of\n",
    "features = [\"Pclass\", \"SibSp\", \"Parch\", \"Age\", \"Sex\", \"Fare\"]\n",
    "\n",
    "# model data\n",
    "x = training_data[features]\n",
    "y = training_data.Survived\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26171419805025714"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preproccessing data\n",
    "\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(x, y, random_state = 1)\n",
    "\n",
    "# accounting for categorical variables-------------------------------------------------------------------------\n",
    "split_object_cols = [col for col in train_x.columns if train_x[col].dtype == \"object\"]\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(train_x[split_object_cols]))\n",
    "OH_cols_valid = pd.DataFrame(OH_encoder.transform(val_x[split_object_cols]))\n",
    "\n",
    "# One-hot encoding removed index; put it back\n",
    "OH_cols_train.index = train_x.index\n",
    "OH_cols_valid.index = val_x.index\n",
    "\n",
    "# Remove categorical columns (will replace with one-hot encoding)\n",
    "num_X_train = train_x.drop(object_cols, axis=1)\n",
    "num_X_valid = val_x.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_cols_valid], axis=1)\n",
    "\n",
    "# accounting for missing values-----------------------------------------------------------------------------------\n",
    "my_imputer = SimpleImputer(strategy = \"median\")\n",
    "final_x_train = pd.DataFrame(my_imputer.fit_transform(OH_X_train))\n",
    "final_x_valid = pd.DataFrame(my_imputer.transform(OH_X_valid))\n",
    "\n",
    "score_dataset(final_x_train, final_x_valid, train_y, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20179372197309417"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing model\n",
    "\n",
    "def score_model(split_model, x_t=final_x_train, x_v=final_x_valid, y_t=train_y, y_v=val_y):\n",
    "    split_model.fit(x_t, y_t)\n",
    "    split_preds = split_model.predict(x_v)\n",
    "    return mean_absolute_error(y_v, split_preds)\n",
    "\n",
    "# find optimal number of estimators based of minimum mean absolute deviation of prediction from split data\n",
    "scores = []\n",
    "n_est = range(1,100)\n",
    "for i in range(len(n_est)):\n",
    "    scores.append(score_model(RandomForestClassifier(n_estimators = n_est[i], random_state=1)))\n",
    "    \n",
    "best_n_estimators = n_est[np.where(scores == np.amin(scores))[0][0]]\n",
    "\n",
    "# define model, test validity\n",
    "model = RandomForestClassifier(n_estimators = best_n_estimators, random_state=1)\n",
    "score_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
       "            oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual model fit\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols = pd.DataFrame(OH_encoder.fit_transform(x[object_cols]))\n",
    "OH_cols.index = x.index\n",
    "num_X = x.drop(object_cols, axis=1)\n",
    "OH_X = pd.concat([num_X, OH_cols], axis=1)\n",
    "\n",
    "final_x = pd.DataFrame(my_imputer.transform(OH_X))\n",
    "\n",
    "model.fit(final_x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using model to make predictions off of test data\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "x_test = test_data[features]\n",
    "\n",
    "OH_encoder_test = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_test = pd.DataFrame(OH_encoder_test.fit_transform(x_test[object_cols]))\n",
    "OH_cols_test.index = x_test.index\n",
    "num_X_test = x_test.drop(object_cols, axis=1)\n",
    "OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)\n",
    "\n",
    "final_x = pd.DataFrame(my_imputer.transform(OH_X_test))\n",
    "\n",
    "test_preds = model.predict(final_x)\n",
    "# print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating output file\n",
    "output = pd.DataFrame({'PassengerId': test_data.PassengerId,\n",
    "                      'Survived': test_preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
